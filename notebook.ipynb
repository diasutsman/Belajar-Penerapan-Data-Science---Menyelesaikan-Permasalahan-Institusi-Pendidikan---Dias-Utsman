{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nama: Dias Utsman\n",
    "- Email: utsmand91@gmail.com\n",
    "- Id Dicoding: dias_utsman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persiapan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menyiapkan library yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.11.11)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/du/CascadeProjects/Belajar Penerapan Data Science - Menyelesaikan Permasalahan Institusi Pendidikan/.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menyiapkan data yang akan diguankan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('data.csv', sep=';')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nStatus distribution:\\n{df['Status'].value_counts()}\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Visualize status distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "status_counts = df['Status'].value_counts()\n",
    "plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', \n",
    "        startangle=90, colors=sns.color_palette('Set2'))\n",
    "plt.title('Distribusi Status Mahasiswa')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Academic performance by status\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(data=df, x='Status', y='Admission_grade')\n",
    "plt.title('Nilai Masuk berdasarkan Status')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(data=df, x='Status', y='Curricular_units_1st_sem_grade')\n",
    "plt.title('Nilai Semester 1 berdasarkan Status')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(data=df, x='Status', y='Curricular_units_1st_sem_approved')\n",
    "plt.title('Unit Disetujui Semester 1 berdasarkan Status')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(data=df, x='Age_at_enrollment', hue='Status', kde=True)\n",
    "plt.title('Distribusi Usia berdasarkan Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "plt.figure(figsize=(14, 10))\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "correlation = numeric_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "sns.heatmap(correlation, mask=mask, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "selected_features = [\n",
    "    'Marital_status', 'Application_mode', 'Course', 'Daytime_evening_attendance',\n",
    "    'Previous_qualification', 'Previous_qualification_grade', 'Nacionality',\n",
    "    'Admission_grade', 'Displaced', 'Educational_special_needs', 'Debtor',\n",
    "    'Tuition_fees_up_to_date', 'Gender', 'Scholarship_holder', 'Age_at_enrollment',\n",
    "    'International', 'Curricular_units_1st_sem_credited', 'Curricular_units_1st_sem_enrolled',\n",
    "    'Curricular_units_1st_sem_evaluations', 'Curricular_units_1st_sem_approved',\n",
    "    'Curricular_units_1st_sem_grade', 'Curricular_units_1st_sem_without_evaluations'\n",
    "]\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[selected_features]\n",
    "y = df['Status']\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(X.isnull().sum().sum())\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(X.isnull().sum().sum())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nPreprocessing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for categorical target\n",
    "label_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}\n",
    "y_train_mapped = y_train.map(label_mapping)\n",
    "y_test_mapped = y_test.map(label_mapping)\n",
    "\n",
    "# Train Random Forest model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train_mapped)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test_mapped, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_mapped, y_pred, target_names=label_mapping.keys()))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_mapped, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_mapping.keys(), \n",
    "            yticklabels=label_mapping.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(len(indices[:10])), importances[indices[:10]], align='center')\n",
    "plt.xticks(range(len(indices[:10])), [X.columns[i] for i in indices[:10]], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 10 most important features\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. {X.columns[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "\n",
    "# Save the model and scaler for the Streamlit app\n",
    "joblib.dump(rf_model, 'model/dropout_prediction_model.joblib')\n",
    "joblib.dump(scaler, 'model/scaler.joblib')\n",
    "print(\"\\nModel and scaler saved to the model directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "print(\"Performing cross-validation...\")\n",
    "cv_scores = cross_val_score(rf_model, X_train_scaled, y_train_mapped, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Per-class evaluation metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_mapped, y_pred, average=None)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': list(label_mapping.keys()),\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "})\n",
    "print(\"\\nPer-class performance metrics:\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Compare with baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy.fit(X_train_scaled, y_train_mapped)\n",
    "dummy_pred = dummy.predict(X_test_scaled)\n",
    "dummy_accuracy = accuracy_score(y_test_mapped, dummy_pred)\n",
    "\n",
    "print(f\"\\nModel comparison:\")\n",
    "print(f\"Random Forest accuracy: {accuracy_score(y_test_mapped, y_pred):.4f}\")\n",
    "print(f\"Baseline (most frequent) accuracy: {dummy_accuracy:.4f}\")\n",
    "print(f\"Improvement over baseline: {accuracy_score(y_test_mapped, y_pred) - dummy_accuracy:.4f}\")\n",
    "\n",
    "# Model conclusion\n",
    "print(\"\\nModel evaluation conclusion:\")\n",
    "print(\"1. The Random Forest model achieved good accuracy in predicting student dropout.\")\n",
    "print(\"2. Key predictors include first semester performance metrics and admission grades.\")\n",
    "print(\"3. The model significantly outperforms the baseline, indicating it has learned meaningful patterns.\")\n",
    "print(\"4. Cross-validation confirms the model's stability across different data subsets.\")\n",
    "print(\"5. The model can be effectively used to identify at-risk students for early intervention.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Berdasarkan analisis dan model yang telah dikembangkan, beberapa temuan utama dari proyek ini adalah:\n",
    "\n",
    "1. **Faktor akademik sangat berpengaruh**: Performa akademik di semester pertama menjadi prediktor terkuat untuk risiko dropout. Mahasiswa yang gagal dalam beberapa mata kuliah di semester pertama memiliki risiko dropout yang jauh lebih tinggi.\n",
    "\n",
    "2. **Faktor ekonomi berperan penting**: Status beasiswa, status pembayaran biaya kuliah, dan status hutang memiliki korelasi kuat dengan tingkat dropout. Mahasiswa dengan masalah keuangan cenderung memiliki risiko dropout yang lebih tinggi.\n",
    "\n",
    "3. **Demografi mahasiswa perlu diperhatikan**: Usia dan status pernikahan mahasiswa juga berpengaruh terhadap kemungkinan dropout.\n",
    "\n",
    "4. **Nilai masuk berkorelasi dengan keberhasilan**: Terdapat korelasi positif antara nilai masuk (admission grade) dengan kemungkinan mahasiswa menyelesaikan pendidikan.\n",
    "\n",
    "5. **Model dapat memprediksi dropout dengan akurasi baik**: Model prediksi yang dikembangkan mampu memprediksi dropout mahasiswa dengan tingkat akurasi yang cukup baik, dan dapat digunakan untuk mengidentifikasi mahasiswa berisiko dropout sejak dini.\n",
    "\n",
    "Secara keseluruhan, implementasi sistem prediksi dropout ini dapat membantu Jaya Jaya Institut dalam mengidentifikasi mahasiswa yang berisiko dropout sejak dini, sehingga dapat dilakukan intervensi yang tepat untuk mengurangi tingkat dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekomendasi Action Items\n",
    "\n",
    "Berdasarkan temuan dari proyek ini, berikut adalah rekomendasi action items untuk Jaya Jaya Institut:\n",
    "\n",
    "1. **Implementasi Sistem Early Warning**: Mengintegrasikan model prediksi dropout ke dalam sistem akademik untuk mendeteksi mahasiswa berisiko secara otomatis di minggu-minggu awal semester.\n",
    "\n",
    "2. **Program Mentoring Akademik**: Membentuk program mentoring akademik khusus bagi mahasiswa yang teridentifikasi berisiko tinggi dropout, dengan fokus pada mata kuliah yang sering menjadi hambatan.\n",
    "\n",
    "3. **Dukungan Finansial Terstruktur**: Menyediakan program bantuan keuangan dan beasiswa yang lebih terstruktur untuk mahasiswa dengan masalah ekonomi.\n",
    "\n",
    "4. **Workshop Keterampilan Belajar**: Menyelenggarakan workshop reguler tentang keterampilan belajar, manajemen waktu, dan strategi menghadapi ujian, terutama bagi mahasiswa baru.\n",
    "\n",
    "5. **Monitoring Berkelanjutan**: Melakukan monitoring berkelanjutan terhadap performa mahasiswa dan mengukur efektivitas program intervensi yang diterapkan.\n",
    "\n",
    "6. **Pelatihan Staf Akademik**: Memberikan pelatihan kepada dosen dan staf akademik tentang cara mengidentifikasi tanda-tanda awal mahasiswa berisiko dropout dan strategi intervensi yang efektif.\n",
    "\n",
    "7. **Program Transisi Perkuliahan**: Mengembangkan program khusus untuk membantu mahasiswa dalam transisi dari sekolah menengah ke perguruan tinggi, terutama bagi mereka yang berasal dari latar belakang pendidikan yang kurang menguntungkan.\n",
    "\n",
    "8. **Optimasi Kurikulum**: Mengevaluasi dan mengoptimasi kurikulum, terutama untuk mata kuliah di semester awal yang sering menjadi hambatan bagi mahasiswa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
